{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Coefficient: {model.coef_[0][0]}\")\n",
    "print(f\"Intercept: {model.intercept_[0]}\")\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Training MSE: {train_mse}\")\n",
    "print(f\"Training R2: {train_r2}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(X_test, y_test, color='green', label='Testing data')\n",
    "plt.plot(X_test, y_test_pred, color='red', linewidth=2, label='Model')\n",
    "plt.title('Testing Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data[:,:2]\n",
    "y=iris.target\n",
    "\n",
    "X=X[y!=2]\n",
    "y=y[y!=2]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=SVC(kernel='linear',C=0.1)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y,cmap='winter')\n",
    "ax=plt.gca()\n",
    "xlim=ax.get_xlim()\n",
    "ylim=ax.get_ylim()\n",
    "\n",
    "xx=np.linspace(xlim[0],xlim[1],30)\n",
    "yy=np.linspace(ylim[0],ylim[1],30)\n",
    "YY,XX=np.meshgrid(yy,xx)\n",
    "xy=np.vstack([XX.ravel(),YY.ravel()]).T\n",
    "Z=clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(XX,YY,Z,colors='k',levels=[-1,0,1],alpha=0.5,\n",
    "           linestyles=['--','-','--'])\n",
    "plt.title(\"Linear SVM Decision Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "X,y=make_circles(n_samples=300,factor=.3,noise=.1)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y,cmap='winter')\n",
    "ax=plt.gca()\n",
    "xlim=ax.get_xlim()\n",
    "ylim=ax.get_ylim()\n",
    "\n",
    "xx=np.linspace(xlim[0],xlim[1],30)\n",
    "yy=np.linspace(ylim[0],ylim[1],30)\n",
    "YY,XX=np.meshgrid(yy,xx)\n",
    "xy=np.vstack([XX.ravel(),YY.ravel()]).T\n",
    "Z=clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(XX,YY,Z,colors='k',levels=[-1,0,1],alpha=0.5,\n",
    "           linestyles=['--','-','--'])\n",
    "plt.title(\"Non-Linear SVM Decision Boundary with RBF Kernel\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "X,y=make_moons(n_samples=300,noise=0.2)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=SVC(kernel='poly',degree=3,C=1.0)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y,cmap='winter')\n",
    "ax=plt.gca()\n",
    "xlim=ax.get_xlim()\n",
    "ylim=ax.get_ylim()\n",
    "\n",
    "xx=np.linspace(xlim[0],xlim[1],30)\n",
    "yy=np.linspace(ylim[0],ylim[1],30)\n",
    "YY,XX=np.meshgrid(yy,xx)\n",
    "xy=np.vstack([XX.ravel(),YY.ravel()]).T\n",
    "Z=clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(XX,YY,Z,colors='k',levels=[-1,0,1],alpha=0.5,\n",
    "           linestyles=['--','-','--'])\n",
    "plt.title(\"Non-Linear SVM Decision Boundary with Polynomial Kernel\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data[:,:2]\n",
    "y=iris.target\n",
    "\n",
    "X=X[y!=2]\n",
    "y=y[y!=2]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "param_grid={\n",
    "    'C':[0.1,1,10,100],\n",
    "    'gamma':[1,0.1,0.01,0.001],\n",
    "    'kernel':['rbf','poly','sigmoid']\n",
    "}\n",
    "\n",
    "svc=SVC()\n",
    "\n",
    "grid_search=GridSearchCV(estimator=svc,param_grid=param_grid,cv=5,verbose=2,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/content/UniversalBank.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop([\"ID\",\"ZIP Code\"],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Heatmap showing Correlation between all the features\",fontsize=20)\n",
    "sns.heatmap(df1.corr(),annot=True,cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_class=df1[df1.CreditCard==0]\n",
    "zero_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class=df1[df1.CreditCard==1]\n",
    "one_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Income')\n",
    "plt.ylabel('Experience')\n",
    "plt.scatter(zero_class['Income'],zero_class['Experience'],color='green',marker='+')\n",
    "plt.scatter(one_class['Income'],one_class['Experience'],color='red',marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('CCAvg')\n",
    "plt.ylabel('Family')\n",
    "plt.scatter(zero_class['CCAvg'],zero_class['Family'],color='blue',marker='+')\n",
    "plt.scatter(one_class['CCAvg'],one_class['Family'],color='red',marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaled=scaler.fit(df1.drop('CreditCard',axis=1)).transform(df1.drop('CreditCard',axis=1))\n",
    "df_scaled=pd.DataFrame(scaled,columns=df1.columns[:-1])\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_scaled\n",
    "y=df1['CreditCard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "svc=SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred=svc.predict(x_test)\n",
    "print('Model accuracy:{0:0.3f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
    "                       index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier=SVC(kernel='linear').fit(x_train,y_train)\n",
    "y_pred=linear_classifier.predict(x_test)\n",
    "print('Model accuracy:{0:0.3f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
    "                       index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc=SVC(kernel='rbf').fit(x_train,y_train)\n",
    "y_pred=rbf_svc.predict(x_test)\n",
    "print('Model accuracy with rbf kernel:{0:0.3f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
    "                       index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Poly_svc=SVC(kernel='poly').fit(x_train,y_train)\n",
    "y_pred=Poly_svc.predict(x_test)\n",
    "print('Model accuracy with polynomial kernel:{0:0.3f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
    "                       index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Poly_svc=SVC(kernel='sigmoid').fit(x_train,y_train)\n",
    "y_pred=Poly_svc.predict(x_test)\n",
    "print('Model accuracy with polynomial kernel:{0:0.3f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
    "                       index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicate values\n",
    "duplicate_rows = df1.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.sum()}\")\n",
    "duplicates = df1[duplicate_rows]\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate values\n",
    "df2 = df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicates again\n",
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing(null) values again\n",
    "round((df2.isnull().sum()/df2.shape[0])*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers from all rows\n",
    "q1 = df2.quantile(0.25)\n",
    "q3 = df2.quantile(0.75)\n",
    "\n",
    "# Calculate IQR\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Determine outliers\n",
    "is_outlier = (df2 < (q1 - 1.5 * iqr)) | (df2 > (q3 + 1.5 * iqr))\n",
    "\n",
    "# Drop outliers\n",
    "df3 = df2[~is_outlier.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
